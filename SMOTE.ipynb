{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Load Kaggle API credentials\n",
    "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USER')\n",
    "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
    "\n",
    "# Download and unzip dataset\n",
    "!kaggle datasets download -d jtiptj/chest-xray-pneumoniacovid19tuberculosis\n",
    "!unzip -q chest-xray-pneumoniacovid19tuberculosis.zip -d /content/\n",
    "\n",
    "# Define dataset directory\n",
    "DATASET_DIR = \"/content/archive/train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "# Using the training set from the dataset structure: archive/train/\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_dataset_rgb(dataset_dir, image_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted([d for d in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, d))])\n",
    "    label_map = {cls: i for i, cls in enumerate(class_names)}\n",
    "\n",
    "    for cls in class_names:\n",
    "        cls_dir = os.path.join(dataset_dir, cls)\n",
    "        for img_file in os.listdir(cls_dir):\n",
    "            img_path = os.path.join(cls_dir, img_file)\n",
    "            try:\n",
    "                img = load_img(img_path, target_size=image_size)  # RGB by default\n",
    "                img = img_to_array(img)\n",
    "                images.append(img)\n",
    "                labels.append(label_map[cls])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "\n",
    "    return np.array(images), np.array(labels), class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training images shape: (6326, 224, 224, 3)\n",
      "Loaded labels shape: (6326,)\n",
      "Classes found: ['COVID19', 'NORMAL', 'PNEUMONIA', 'TURBERCULOSIS']\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "X, y, class_names = load_dataset_rgb(DATASET_DIR)\n",
    "print(\"Loaded training images shape:\", X.shape)\n",
    "print(\"Loaded labels shape:\", y.shape)\n",
    "print(\"Classes found:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for VGG16\n",
    "X_preprocessed = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the VGG16 model without the top classification layers for feature extraction\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m198/198\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2888s\u001b[0m 15s/step\n",
      "Extracted features shape: (6326, 512)\n"
     ]
    }
   ],
   "source": [
    "# Extract deep features from images\n",
    "features = base_model.predict(X_preprocessed)\n",
    "features = global_avg_pool(features).numpy()\n",
    "print(\"Extracted features shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE - features shape: (15500, 512)\n",
      "After SMOTE - labels shape: (15500,)\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE on the extracted features to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "features_bal, y_bal = smote.fit_resample(features, y)\n",
    "print(\"After SMOTE - features shape:\", features_bal.shape)\n",
    "print(\"After SMOTE - labels shape:\", y_bal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved as 'features_balanced.npy' and 'labels_balanced.npy'.\n"
     ]
    }
   ],
   "source": [
    "# Save the balanced features and labels \n",
    "np.save('features_balanced.npy', features_bal)\n",
    "np.save('labels_balanced.npy', y_bal)\n",
    "print(\"Balanced dataset saved as 'features_balanced.npy' and 'labels_balanced.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
